from langchain_ollama import OllamaLLM
import base64
from io import BytesIO
llm = OllamaLLM(model="llama3.1")


def call_llama_combine_exp7(caption,full_image_caption):
    response = llm.invoke(f"""
        Caption 1 (Top Left): {caption[0]},
        Caption 2 (Top Right): {caption[1]},
        Caption 3 (Bottom Left): {caption[2]},
        Caption 4 (Bottom Right): {caption[3]},
        Full Image Caption: {full_image_caption},
        A caption engine was given 4 different sections of images and was asked to generate captions for it. Above are the captions generated by it. The caption was
        also generated for the full image.
        Your job is to generate the most coherent caption describing the full image with the help of the full image caption and the captions given above of the image divided into
        equal parts.
        Your response should not contain any other information aside from the caption
        Only include the caption in your response and nothing else
        Do not include any unwanted intro and any unwanted information in the response aside from the caption
    """)
    return response

def call_llama_exp4(OCR_INFO,OBJECT_INFO,CAPTION):
    response = llm.invoke(f"""
    You are a powerful multimodal model and you should generate detailed description of an image using
    external information such as:
    OCR_INFORMATION: {OCR_INFO},
    ---------------------------------------------------
    OBJECT DETECTION INFORMATION: {OBJECT_INFO['<OD>']},
    ---------------------------------------------------
    SMALL CAPTION: {CAPTION['<CAPTION>']},
    ---------------------------------------------------

    Your job is to utilize all this information to generate one small caption describing the image. The caption can be of 1-5 lines and not much longer
    Your response should not contain any other information aside from the caption
    Only include the caption in your response and nothing else
    Do not include any unwanted intro and any unwanted information in the response aside from the caption
    """)
    return response

def call_llama_combine_exp6(caption):
    response = llm.invoke(f"""
        Caption 1 (Top Left): {caption[0]},
        Caption 2 (Top Right): {caption[1]},
        Caption 3 (Bottom Left): {caption[2]},
        Caption 4 (Bottom Right): {caption[3]},
        A caption engine was given 4 different sections of images and was asked to generate captions for it. Above are the captions generated by it. 
        Your job is to generate the most coherent caption describing the full image with the help of captions given above of the image divided into
        equal parts. 
        Your response should not contain any other information aside from the caption
        Only include the caption in your response and nothing else
        Do not include any unwanted intro and any unwanted information in the response aside from the caption
    """)
    return response


def call_llama_with_extra_data_exp5(OCR_INFO,OBJECT_INFO,CAPTION,extra_tags, extra_detections):
    query = f"""
    You are a powerful multimodal model and you should generate detailed description of an image using
    external information such as:
    OCR_INFORMATION: {OCR_INFO['<OCR>']},
    ---------------------------------------------------
    IMAGE_TAGS: {OBJECT_INFO['<OD>']['labels']},
    ---------------------------------------------------
    OBJECT DETECTION INFORMATION: {OBJECT_INFO['<OD>']},
    ---------------------------------------------------
    Original Caption: {CAPTION['<CAPTION>']},
    ---------------------------------------------------
    Extra Tags: {extra_tags},
    ---------------------------------------------------
    Extra object detection information: {extra_detections},
    ---------------------------------------------------
    Your job is to utilize all this information to generate one small caption describing the image. The caption can be of 1-5 lines and not much longer
    Your response should not contain any other information aside from the caption
    Only include the caption in your response and nothing else
    Do not include any unwanted intro and any unwanted information in the response aside from the caption
    """
    # print(query)
    response = llm.invoke(query)
    return response


def call_llama_exp8(OCR_INFO,OBJECT_INFO,IMAGE_TAGS,CAPTION):
    print(CAPTION['<DETAILED_CAPTION>'])
    response = llm.invoke(f"""
    You are a powerful multimodal model and you should generate detailed description of an image using
    external information such as:
    OCR_INFORMATION: {OCR_INFO['<OCR>']},
    ---------------------------------------------------
    IMAGE_TAGS: {IMAGE_TAGS},
    ---------------------------------------------------
    OBJECT DETECTION INFORMATION: {OBJECT_INFO['<OD>']},
    ---------------------------------------------------
    EXISTING CAPTION: {CAPTION['<DETAILED_CAPTION>']},
    ---------------------------------------------------

    Your job is to utilize all this information to generate one small caption describing the image. The caption can be of 1-5 lines and not much longer
    Your response should not contain any other information aside from the caption. Use the existing caption given to you to treat as world knowledge. But only use
    entities/nouns in captions that is present in the Image Tags or the Object Detection Information. So basically tune the existing caption to reduce hallucinations
    by considering Image Tags and Object Detection Information as ground truth
    Only include the caption in your response and nothing else
    Do not include any unwanted intro and any unwanted information in the response aside from the caption
    """)
    return response



